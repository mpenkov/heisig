{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 thousand unique Kanji, each consisting of one or more radicals.\n",
    "There are 254 unique radicals.\n",
    "\n",
    "I'm thinking:\n",
    "\n",
    "1. Represent each Kanji as a \"bag-of-radicals\"\n",
    "2. Learn a vector for each radical\n",
    "3. To get the vector for a Kanji, sum the vectors of its radicals\n",
    "\n",
    "Once we have vectors for Kanji, we can calculate similarity/difference, etc. For example:\n",
    "\n",
    "# 雪 (snow) vs 電 (electricity)\n",
    "\n",
    "- 雪 ['ヨ', '雨']\n",
    "- 電 ['雨', '田', '乙']\n",
    "\n",
    "For learning, I was thinking of using Word2Vec.\n",
    "Each Kanji would be a \"sentence\".\n",
    "Each radical would be a \"word\".\n",
    "\n",
    "# Questions\n",
    "\n",
    "- How is this better than our previous approaches?\n",
    "- What is Word2Vec actually learning, and _how_?\n",
    "- Is the training data sufficient? Can we improve it somehow?\n",
    "- Is the order of words in a sentence important? KRAD doesn't enforce an order..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "def parse_krad():\n",
    "    with gzip.GzipFile('kradfile.gz') as fin:\n",
    "        krad = fin.read().decode('euc-jp')\n",
    "    for line in krad.split('\\n'):\n",
    "        if line and line[0] == \"#\":\n",
    "            continue\n",
    "        elif ' : ' in line:\n",
    "            kanji, radicals = line.split(' : ')\n",
    "            radicals = radicals.split(' ')\n",
    "            yield kanji, radicals\n",
    "        \n",
    "krad_dict = dict(parse_krad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['｜', '一', '口'],\n",
       " ['｜', '一', '口'],\n",
       " ['女', '土'],\n",
       " ['一', '口', '亅', '阡'],\n",
       " ['衣', '口', '亠'],\n",
       " ['心', '爪', '冖', '夂'],\n",
       " ['矢', '厶', '扎', '乞'],\n",
       " ['一', '口', '女', '个'],\n",
       " ['｜', '込', '二', '夂'],\n",
       " ['人', '大', '二', '癶', '艾', 'ノ']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(krad_dict.values())\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6355"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "counter = collections.Counter()\n",
    "for sent in sentences:\n",
    "    counter.update(sent)\n",
    "len(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ヨ', '雨']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krad_dict['雪']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['雨', '田', '乙']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krad_dict['電']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133272, 257000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "model = Word2Vec(size=100, min_count=1)\n",
    "model.build_vocab(sentences, keep_raw_vocab=True)\n",
    "\n",
    "def jumble(sent, iterations=10):\n",
    "    import random\n",
    "    for i in range(iterations):\n",
    "        for s in sent:\n",
    "            random.shuffle(s)\n",
    "            yield s\n",
    "\n",
    "# model.train(sentences, total_examples=len(sentences), epochs=100)\n",
    "model.train(jumble(sentences), total_examples=len(sentences) * 10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6431980119578202"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def kanjivec(k):\n",
    "    # TODO: weigh each radical by its stroke count?\n",
    "    vector = np.zeros((model.wv.vector_size,))\n",
    "    # print(k, krad_dict[k])\n",
    "    for rad in krad_dict[k]:\n",
    "        # print(k, rad, model.wv[rad])\n",
    "        vector += model.wv[rad]\n",
    "    vector /= len(krad_dict[k])\n",
    "    # print(vector)\n",
    "    return vector\n",
    "\n",
    "def kanjisim(k1, k2):\n",
    "    return np.linalg.norm(kanjivec(k1) - kanjivec(k2))\n",
    "\n",
    "kanjisim('愛', '受')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('鶻', 0.2535393381398565),\n",
       " ('傅', 0.2651712946052006),\n",
       " ('鰤', 0.28658093164707327),\n",
       " ('鯖', 0.2967796693262081),\n",
       " ('鴎', 0.30603099186896016),\n",
       " ('鰊', 0.3080451830199496),\n",
       " ('駭', 0.31056915260175655),\n",
       " ('嵎', 0.3160042276736563),\n",
       " ('駲', 0.31697914730156396),\n",
       " ('黜', 0.3180580704107598)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similar(target, n=10):\n",
    "    d = {k: kanjisim(target, k) for k in krad_dict if k != target}\n",
    "    best = sorted(d.items(), key=lambda x: x[1])\n",
    "    return best[:n]\n",
    "\n",
    "find_similar('驪')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
